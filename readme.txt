This project implements a Lexical Analyzer and Parser for a low-level assembly language. It uses Lex for tokenizing the input and Yacc/Bison for parsing the tokens to validate and process assembly instructions.
Files

1) tokenizer.l :
	This file contains the Lex specifications to tokenize the assembly language input. It defines the following:
		Patterns (regular expressions) for recognizing assembly language syntax, such as:
        		Instructions (mov, sub, add, cmp, etc.)
        		Registers (eax, ebx, etc.)
        		Memory references (dword[ ], [ ])
        		Values (numeric literals)
        		Symbols, strings, and sections (.bss, .data, .text)
        		Punctuation like commas and colons

	Actions:
        	Extracts tokens and assigns them to yylval for further processing in the parser.
        	Sets flags (isReg, isMem, flag) for specific states.

2) parser.y :
	This file contains the Yacc/Bison grammar rules to parse the tokens generated by tokenizer.l. It defines:
		Assembly language constructs:
        		Instructions with operands
        		Registers and memory access
        		Data declarations (db, dd, resb, resd)
        		Sections (.bss, .data, .text)
        		Labels and symbols
		
	Tokens:
        	Tokens are passed from tokenizer.l and processed according to grammar rules.

    	Actions:
        	Processes and validates the structure of assembly instructions.
        	Uses the yylval structure to store token information like operand names.

How It Works : 

    Lexical Analysis:
        tokenizer.l scans the input assembly file and identifies tokens using regular expressions.

    Parsing:
        parser.y uses grammar rules to ensure that the tokenized assembly input conforms to valid syntax.
